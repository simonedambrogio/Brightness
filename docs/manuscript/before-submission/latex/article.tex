\documentclass{article}


\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{fancyhdr}       % header
\usepackage{graphicx}       % graphics
\graphicspath{{media/}}     % organize your images and other figures under media/ folder

% Remove section numbering
\setcounter{secnumdepth}{0}

%Header
\pagestyle{fancy}
\thispagestyle{empty}
\rhead{ \textit{ }} 

% Update your Headers here
% \fancyhead[LO]{Running Title for Header}
% \fancyhead[RE]{Firstauthor and Secondauthor} % Firstauthor et al. if more than 2 - must use \documentclass[twoside]{article}

% Remove "A PREPRINT" text from under the title
\renewcommand{\undertitle}{}

% Make the horizontal lines above and below the title thinner
\makeatletter
\renewcommand{\@toptitlebar}{
  \hrule height 1\p@
  \vskip 0.25in
  \vskip -\parskip%
}
\renewcommand{\@bottomtitlebar}{
  \vskip 0.29in
  \vskip -\parskip
  \hrule height 1\p@
  \vskip 0.09in%
}
\makeatother

  
%% Title
\title{A template for Arxiv Style
%%%% Cite as
%%%% Update your official citation here when published 
% \thanks{\textit{\underline{Citation}}: 
% \textbf{Authors. Title. Pages.... DOI:000000/11111.}} 
}

\author{
    Simone D'Ambrogio \\
%   Department of Experimental Psychology \\
    University of Oxford \\
%   Oxford, UK \\
%   \texttt{simone.dambrogio@psy.ox.ac.uk} \\
  %% examples of more authors
   \And
    Michael Platt \\
%   Affiliation \\
    University of Pennsylvania \\
%   City\\
%   \texttt{email@email} \\
    \And
    Feng Sheng \\
    Zhejiang University
}


\begin{document}
\maketitle


\begin{abstract}
Visually salient information can disproportionately sways economic choice, a phenomenon typically attributed to gaze bias. Here we demonstrated that gaze bias is rarely a driver of this phenomenon. In an eye-tracking experiment, participants decided whether to accept gambles of equal odds to win and lose money, with the relative visual salience of potential gain versus potential loss manipulated via brightness. Robust salience effect on choice was observed: gambles were more frequently accepted when potential gain, rather than potential loss, was brighter. We did find a gaze bias toward the brighter attribute, but it accounted for only 6\% variances of the salience effect across trials and x\% variances of the salience effect across individuals. We postulated that visual salience impacts economic choice not just by altering gaze allocation but also by directly modulating subjective magnitude representation of stimuli, which was formalizable by a computational framework that integrated gaze-dependent evidence accumulation and convolved neural network translating pixel-level visual input into subjective magnitude representation. Our study underscores the multifaceted cognitive processes underlying visual salience effect and demonstrates simple manipulations of visual displays that can be widely used to impact economic choice.
\end{abstract}


% keywords can be removed
\keywords{First keyword \and Second keyword \and More}


\section{Introduction}
(describe the visual salience effect; mention brightness)
Making rational economic choices is fundamental to navigating daily life. From selecting consumer goods to making investment decisions, we constantly evaluate options, often relying heavily on our visual system to gather necessary information. We often rely on our visual system to sample information when making economic choice \cite{pearson_attentional_2022}. Interestingly, our choice is often susceptible to visual salience of information that are irrelevant to economic outcomes \cite{ittiComputationalModellingVisual2001, wolfeFiveFactorsThat2017}. Information visually salient in brightiness or physical size often has a greater impact on choice \cite{bordaloSalience2022}. For example, laboratory studies find that when faced with risky choice involving potential gains and losses, people are more likely to take risk when gains are displayed with a brighter color or in a larger font size, but to avoid risk when losses are brighter or font-larger \cite{vanunuHowTopdownBottomup2021}. Relatedly, when choosing from alternatives for food consumption, people are more likely to choose the item that is visually prominent \cite{gidlofLookingBuyingHow2017, liPredictableEffectsVisual2022, milosavljevicRelativeVisualSaliency2012}. Ouside laboratories, the salience effect on choice has also been broadly observed in the field like shopping \cite{blakePriceSalienceProduct2021a, bollingerCaloriePostingChain2011, taubinskyAttentionVariationWelfare2018} (Blake et al., 2021; Bollinger et al., 2011; Taubinsky \& Rees-Jones, 2018), saving \cite{badoerCanSeeClearly2020, choiSmallCuesChange2017} and stock exchanging \cite{frydmanImpactSalienceInvestor2020}.

(describe the attention account: indirect path)
In value-based choices, items receiving more cumulative gaze are more likely to be chosen, an effect formalized in influential computational frameworks like the attentional Drift Diffusion Model (aDDM) which propose that attention down-weights the evidence accumulation process for the unattended item or attribute \cite{krajbichVisualFixationsComputation2010}. This attentional influence extends beyond simple consumer choice, shaping decisions in domains like prosocial behavior, where directing attention towards others' outcomes can foster cooperation \cite{lugrinManipulatingAttentionFacilitates2025}, and significantly impacting preferences in risky decision-making paradigms \cite{shengDecomposingLossAversion2020}. Given these findings, the prevailing view often attributes the impact of visual factors, particularly stimulus salience primarily to their capacity to capture gaze, which subsequently biases choice through these established attentional amplification mechanisms \cite{bordaloSalience2022}.

(propose the perception account: direct path)
However, attention may not be the sole determinant shaping our economic decisions. Other cognitive processes, occurring even before or alongside attentional allocation, can introduce biases. For instance, a recent study suggests that the neural representation of numerical magnitude itself, potentially involving regions like the parietal cortex, can be subject to biases that influence subsequent value judgments, independent of overt attentional deployment \cite{hollanderRiskPreferencesCausally2025}. This highlights the critical need to determine whether visual salience influences choice only by directing gaze, or if it might also exert a more direct influence, perhaps by altering the underlying representation of the choice attributes themselves.

I would suggest insert a paragraph here or revise the last paragraph to mention 1) Colin Camerer QJE paper \cite{liPredictableEffectsVisual2022} that use salience algorithm of computer vision to predict economic choice, and 2) the CNN algorithm we used to translate perceptual inputs into values \cite{jaffeImagecomputableModelSpeeded2025}. 

(propose the integrative account: define direct and indirect path)
To address this gap, we investigated the pathways through which visual salience (manipulated via brightness or font-size) influences value-based choices in a risky gambling task involving potential gains and losses. We analyzed participants' choices and continuously monitored their eye movements. Our results reveal a multi-faceted influence of salience. First, confirming prior work, we found that making the gain or loss visually salient systematically biased participants' choices (Fig. 2). Second, we observed that salience indeed influenced gaze patterns, although intriguingly, brightness and font-size manipulations elicited opposing gaze responses (Fig. 3).

Crucially, using causal mediation analysis, we formally disentangled the pathways linking salience to choice (Fig. 4). This revealed that while gaze patterns partially mediated the effect (the indirect pathway), a substantial portion of salience's influence occurred independently of measured gaze (the direct pathway, ADE). To probe the mechanism underlying this gaze-independent effect, we employed a computational modeling approach combining deep convolutional neural network for visual processing with gaze-dependent evidence accumulation. Analyzing the internal representations learned by the visual processing module, before gaze information was incorporated, we found that salience systematically altered the representation of the gamble's value itself (captured by the first principal component of network activations).
Together, these findings suggest that while salience does influence choice via gaze mediation, it also exerts a significant, direct influence by modulating the internal representation of value early in the decision process, upstream of attentional amplification. This highlights a deeper interplay between visual perception, valuation, and attention in shaping economic choices.
To maximize economic outcomes in the gambling task, participants should evaluate the potential gains and losses based solely on their magnitudes and the associated probabilities (here, 50/50) to estimate the expected value of accepting the gamble. The visual presentation of these potential outcomes is irrelevant to the economic value and thus should not influence choice. However, a few studies suggest that such visual salience manipulations can indeed bias decisions. Here, we analyzed behavioral and eye-tracking data from two experiments to investigate how salience (manipulated via brightness or font-size) impacts gaze allocation and subsequent choices in a risky gambling task.


\section{Results}

\subsection{Visual Salience Biases Risky Choice}

We first investigated how the salience manipulation influenced participants' choices to accept or reject the gambles (Fig. ). As expected, the probability of accepting a gamble generally increased with the magnitude of the potential gain and decreased with the magnitude of the potential loss (Fig. ). Critically, however, choice probability was systematically biased by the salience manipulation: across both brightness, participants were significantly more likely to accept a given gamble when the potential gain was salient (brighter) compared to when the potential loss was salient (Fig. ).

\subsection{Visual Salience Biases Gaze Allocation}
We then examined how the salience manipulation influenced participants' gaze patterns, as changes in attention allocation could potentially explain these choice effects (Fig. ). Consistent with the hypothesis that salience guides attention, making an attribute brighter consistently directed more gaze towards it. Specifically, the probability of looking at the gain attribute was significantly higher when the gain was brighter compared to when the loss was brighter (beta = ..., Fig. ). The probability of looking at the gain attribute was lower when the gain was larger (salient) compared to when the loss was larger (beta = ..., Fig. ). Independent of salience, our mixed-effect logistic regression analyses also revealed that gaze allocation was sensitive to the attribute magnitudes themselves: the probability of looking at the gain attribute increased with the magnitude of the potential gain (beta = ...) and decreased with the magnitude of the potential loss (beta = ... in Fig.).

Consistent with these overall gaze patterns, an analysis of the initial orienting of attention revealed that the probability of first fixating the gain attribute followed the same pattern as a function of salience (Supplementary Fig. SX). First fixations were more likely to be directed towards the brighter attribute in the brightness condition but towards the smaller attribute in the font-size condition (beta = ..., Supplementary Fig. SX).

To understand how these gaze allocation patterns evolved and whether they were transient or sustained, we examined the temporal dynamics from trial onset. This analysis revealed that the differential allocation of gaze emerged early in the decision process (around 0.5s) and persisted throughout the observed time window, further illustrating the dissociation: the proportion of time spent gazing at the brighter attribute increased over time (Fig. ), whereas the proportion of time spent gazing at the smaller attribute increased over time in the font-size condition (Fig. ).

Taken together, these results demonstrate that while brightness guides gaze as expected, smaller font size unexpectedly captured more visual attention during risky choice in our task, with these effects influencing both initial orienting and sustained allocation of attention.

\subsection{Gaze Partially Mediates the Effect of Salience on Choice}

So far we have established that visual salience biases both participants' choices (Fig. 2A,B) and their gaze allocation patterns (Fig. 2C-F). A critical question is how these effects are interconnected. Specifically, we need to determine whether the influence of salience on choice operates exclusively by changing gaze patterns, or if salience also exerts an influence on choice through other mechanisms independent of gaze. To disentangle these possibilities, we employed a causal mediation framework (Fig. 3).

Within this framework, we considered three main scenarios. First (Fig. 3A, H1), salience might influence choice solely by altering gaze allocation; here, the entire effect of salience would be explained by changes in looking patterns via the indirect pathway mediated by gaze. Second, (Fig. 3A, H2), salience might influence choice through mechanisms entirely separate from the measured gaze behavior; this direct pathway represents the portion of salience's influence not accounted for by gaze mediation, suggesting effects channeled through routes other than the measured gaze patterns. Finally (Fig. 3A, H3), salience could influence choice through both routes simultaneously: partly by changing gaze patterns and partly through other mechanisms independent of gaze.

Mediation analysis quantifies these pathways, estimating the Average Causal Mediation Effect (ACME) for the indirect pathway via gaze, and the Average Direct Effect (ADE) for the pathway independent of gaze. Thus, finding only a significant ACME would support H1, only a significant ADE would support H2, and significant effects for both ACME and ADE would support H3.

To formally test these competing hypotheses, we performed a Bayesian mediation analysis, modeling the effect of salience on choice as mediated by the proportion of gaze on the gain attribute, while allowing effects to vary by salience condition (e.g. brightness, and font-size).

Consistent with Hypothesis 3, the results revealed significant effects for both pathways (Fig. 2D). We found a significant ACMEs that reflected the opposing effects of salience on gaze allocation: the indirect effect was negative in the brightness condition (ACME = ) but positive in the font-size condition (ACME = ).

Crucially, supporting a direct influence of salience independent of gaze, the analysis also revealed a significant ADE in both conditions. In the loss salient trials, the log-odds of acceptance was significantly lower in both, the brightness condition (ADE = ), and in the font-size condition (ADE = ).

Together, the finding that the direct effect was significant, consistently negative, and substantially larger than the indirect effect across both manipulations provides strong evidence against the hypothesis that salience influences choice solely via gaze allocation. Instead, the results indicate that visual salience biases risky choices both indirectly, by altering gaze patterns, and more predominantly, through a direct mechanism independent of the observed gaze behavior.

I would suggest add a paragraph here or other place to describe the correlation of individual difference in gaze bias and individual difference in choice bias, so that we could know how well the gaze bias can explain the variation of the salience effect at the individual level in addition to the trial-level variation shown by the mediation analyses. 

To better understand the mechanisms underlying these choice effects, particularly the indirect pathway involving attention, we next examined how the salience manipulations influenced participants' gaze patterns.

\subsection{Salience Modulates Internal Value Representations Independent of Gaze}

Our mediation analysis revealed a substantial portion of salience's influence on choice occurs independently of measured gaze patterns (Fig. ). This raises the question of what cognitive mechanism underlies this gaze-independent effect.

One hypothesis is that visual salience might directly bias the brain's internal representation of the magnitudes associated with gains and losses. This aligns with growing evidence suggesting that economic choices are sensitive to how numerical magnitudes are perceived and neurally encoded, potentially involving biases or noise in these representations \cite{dehollanderRiskPreferencesCausally2025}. Therefore, we explored whether visual salience could be one factor that directly modulates these internal magnitude representations before gaze influences the deliberation process.

To test this, we employed a computational modeling approach that simulates the decision process directly from the visual input (Fig. 4A). Specifically, we adapted the Visual Accumulator Model (VAM) framework \cite{jaffeImagecomputableModelSpeeded2025}, which uses a Convolutional Neural Network (CNN) to extract decision-relevant features directly from raw pixel input, passing these features as drift rates to a Linear Ballistic Accumulator (LBA) model. To account for attentional effects, we modified this framework by incorporating gaze-dependent discounting of the evidence derived from the CNN output, conceptually similar to the Gaze-weighted Linear Accumulator Model (GLAM) \cite{molterGLAMboxPythonToolbox2019}, where the effective drift rate depends on the gaze proportion towards an item and a fitted gaze-bias parameter $\lambda$. In other words, this model has two key components. First, a visual processing module (a Convolutional Neural Network, or CNN) that act like an artificial visual system. It takes the raw pixels of the gamble image as input and learns to extract decision-relevant features, similar to how the human brain processes visual scenes to identify numbers and their visual properties (like brightness or font size, reference …). Second, a gaze-modulated accumulation module (based on the Linear Ballistic Accumulator, LBA)  that simulates the process of accumulating evidence for accepting or rejecting the gamble over time. Crucially, the rate of evidence accumulation is influenced by the features extracted by the CNN and by the participant's measured gaze patterns (specifically, evidence from the non-attended option is discounted, similar to established gaze-weighted accumulator models like aDDM or GLAM).

We trained separate VAMs for the brightness and font-size experiments, fitting them to participants' choices and reaction times. The power of this approach is that, once trained, we can examine the model's internal representation to understand how it processes the visual information. Specifically, we looked at the information represented within the CNN just before it feeds into the final evidence accumulation stage. This provides insight into the model's internal representation of the gamble's value, prior to the gaze-dependent modulation.

We found that the best-fitting gaze-bias parameter $\lambda$ in the accumulation module was less than 1 for both brightness ($\lambda = 0.73$) and font-size ($\lambda = 0.73$) experiments. This confirms that the model captured the attentional discounting effect, where participants down-weighted information they were not looking at, consistent with the gaze-mediated pathway identified earlier.

To probe the internal value representations learned by the model, we extracted the activations from the penultimate layer of the trained CNN (i.e., the input to the final drift-rate mapping layer) for each trial. This layer was chosen because, analogous to higher stages in cortical processing hierarchies, it is expected to contain the most abstract, integrated representation of task-relevant variables before the final output transformation. 

We applied Principal Component Analysis (PCA) to these high-dimensional activations to identify the principal dimensions along which the network's internal state varied across trials. This analysis revealed that the first principal component (PC1), capturing the largest proportion of variance, strongly correlated with the objective value difference between the gain and loss options (brightness r = …, p < 0.001, font-size r = …, p < 0.001), suggesting it captures the model's internal assessment of the gamble's overall value.

Most importantly, we examined how this internal value representation (PC1 score) was affected by salience (Fig. 4B). For any given objective value difference, the PC1 score was systematically higher when the gain was salient compared to when the loss was salient. This pattern held for both the brightness (Fig. 4B left) and font-size (Fig. 4B right) conditions.

This finding provides computational evidence supporting the hypothesis that visual salience directly modulates the internal representation of value within the visual processing stage itself (as captured by PC1). Crucially, this modulation occurs before the influence of gaze (captured by the parameter $\lambda$ in the accumulation stage) takes effect. It suggests that the gaze-independent pathway (ADE) identified in the mediation analysis may operate (Fig. 3B), at least in part, by altering how the brain encodes the subjective magnitude of potential gains and losses based on their visual presentation, over and above the effect of attentional allocation. This offers a deeper mechanistic insight into how seemingly irrelevant visual features can alter the valuation process itself, biasing choices beyond their influence on overt attention.

\section{Materials and Methods}

\paragraph{Participants.} 
We analyzed data from 132 participants (67 females; 18–80 y old, M±SD=48.03±17.60) experiment. All participants provided informed consent before the start of the experiment. All participants had normal or corrected-to-normal vision.

\paragraph{Procedure.} In the gambling task, participants decided whether to accept or reject gambles of equal chance of winning and losing money on a computer (Fig. 1A). We used the JavaScript library jsPsych to code the task, and Prolific to recruit participants. Each trial started with a 2 $\sim$ 4 seconds gaze fixation period, followed by a gamble with the amounts of potential gain and loss displayed on the left and right hand side of the screen. In 50\% of the trials the potential gain was salient, while in the remaining 50\% the potential loss was salient. We used two types of salience manipulation, brightness and font-size. In the brightness manipulation, the salient attribute was brighter than the not salient, while in the font-size manipulation, the salient attribute was bigger than the not salient. Participants were given unlimited time to make the decision by pressing one of two keys. The gambles were not immediately resolved post decision. The amounts of potential gain and loss ranged from \$3 to \$9, with \$1 increment. Each resulting unique gamble pair was presented twice, once in which the potential gain was salient and once in which the potential loss was salient, for a total of 98 trials. The presentation order of the trials was randomized across participants. Participants received a fixed endowment of \$4 for their participation. Moreover, they had an additional dollar to their disposal, and they were instructed that at the end of the experiment, one trial (out of 98) would be randomly selected and a payment would be made according to their actual decision. If the selected gamble was rejected, participants were left with the original \$4 + \$1. If the gamble was accepted and they won it, the amount of gain was divided by 10 and added to the tally. If instead they lost, the amount of loss was divided by 10 and subtracted from it. Thus, decisions directly impacted payments, making the task incentive-compatible.

\paragraph{Online Eye Tracking Using Web Cameras.} We recorded gaze fixations using WebGazer.js, a JavaScript library that uses common webcams to infer eye-gaze locations in real time. WebGazer.js runs entirely in the client browser, and only the coordinates of the gaze position were transmitted and saved on our online server. For the software to predict the gaze position on the screen, a thirteen-points calibration-validation scheme was used. Subjects had three chances to achieve a 70\% accuracy. After the third attempt, the gambling task started regardless of the validation outcome. After 24, 48 and 72 trials, the gamble task was designed to stop to allow participants to rest their eyes. After each break, participants repeated the calibration and validation procedure only once, and they went on with the task regardless of the validation accuracy.

\paragraph{Preprocessing of Webcam-Based Gaze Position Data.} A total of 335 subjects participated in one of the two experimental conditions. Each participant completed 98 trials, thus we collected a total of 32830 trials. We used four exclusion criterions to ensure good data quality. First, we removed all trials whose response time was lower than 300 ms (1.4\% trials). Second, we removed all trials in which the sampling rate was less than 8Hz (19\% trials). Third, whenever WebGazer does not classify the eyes from the webcam input, it returns a NA rather than an x and y coordinate. We removed all trials in which the NAs were more than 50\% of the total number of samples (0.6\% trials). Lastly, we defined two regions of interest (ROIs), one for each attribute. We discarded all trials with a summed fixation time outside of the ROIs greater than 80\% of the total decision time (28.8\% trials). These exclusion criteria led us to a final sample of 257 participants, with an average number of trials of 59.7 ± 27.3 (mean ± standard deviation). For the survived trials, we linearly interpolated missing data and denoised gaze positions using a 300-ms-long median filter.

\paragraph{Regression and Mediation Analyses.} We used the R package brms \cite{burknerBrmsPackageBayesian2017} to perform all Bayesian multilevel regression models. For the causal mediation analysis, we specified a Bayesian multilevel mediation model to examine the extent to which the effect of salience on choice was mediated by gaze allocation. The model consisted of two simultaneous equations. The first equation modeled the mediator, the z-scored proportion of gaze to the loss attribute, as a function of an interaction between the salience manipulation (loss salient vs. gain salient) and salience type (brightness vs. font-size), as well as z-scored gain and loss magnitudes. This model included random intercepts and random slopes for all fixed effects by participant. The second equation modeled the outcome variable, choice (accept/reject), using a Bernoulli distribution with a logit link function. Predictors for choice included the interaction between salience and salience type, the mediator proportion of gaze to the loss attribute, and z-scored gain and loss magnitudes. This model also included random intercepts and random slopes for all fixed effects by participant. Models were run with 4 chains, each for 20,000 iterations, with the first 10,000 iterations discarded as warmup, and an \texttt{adapt\_delta} parameter of 0.95 to ensure good sampling.

\paragraph{Computational Modeling.} To investigate the mechanisms by which salience influences choice, we employed a Visual Accumulator Model (VAM) adapted from Jaffe et al. (2020). This model (illustrated in Fig. 4A) integrates a visual processing module with a decision module to simulate choices and reaction times directly from raw pixel-level image inputs.

The visual processing module was a Convolutional Neural Network (CNN). The CNN architecture consisted of six convolutional layers with 64, 64, 128, 128, 128, and 256 features respectively, followed by one fully-connected layer with 1024 units. This network culminated in an output layer that produced two mean drift rates for the decision module, corresponding to the 'accept' and 'reject' options of the gamble. To enhance robustness and prevent overfitting to specific pixel configurations, the training dataset was expanded through data augmentation, creating five variations of each original stimulus image. This augmentation involved randomly displacing each numerical attribute (gain and loss) within a circular region and applying a random rotation (between -15 and +15 degrees) to each. To potentially leverage pre-existing visual feature extractors, the initial convolutional layers of the CNN was be initialized with weights from a VGG16 model \cite{simonyanVeryDeepConvolutional2015} pre-trained on ImageNet \cite{dengImageNetLargescaleHierarchical2009}, with these weights being fine-tuned during training.

The decision module was a Linear Ballistic Accumulator (LBA) model \cite{brownSimplestCompleteModel2008} with two accumulators. The LBA component was characterized by parameters for non-decision time $t0$, threshold-related component $c$, and the upper bound of the uniform distribution for starting point variability $a$, where the decision threshold $b$ is defined as $b=c+a$. The standard deviation of drift rates was fixed to 1. Crucially, to incorporate attentional effects, the mean drift rates from the CNN were modulated by gaze. If $v_k$ was the mean drift rate for accumulator $k$ (accept or reject) derived from the CNN, and $g_k$ was the proportion of gaze to the choice attribute primarily informing accumulator $k$, the effective drift rate for that accumulator was calculated as $v_k  (g_k+(1-g_k )\lambda)$, where $lambda$ is a fitted gaze-bias parameter. A $lambda$ value less than 1 indicates that evidence from the attribute not being looked at is down-weighted.

The entire VAM, including the CNN parameters and the posterior distributions of the LBA parameters ($a$, $c$, $t0$, $\lambda$), was jointly fitted to each participant's trial-level data (stimuli, choices, reaction times, and gaze proportions) using a Bayesian framework. This involved variational inference for the LBA parameters and optimization of the CNN parameters to maximize the evidence lower bound (ELBO), effectively learning visual representations and decision parameters that best explained the observed behavior.

%Bibliography
\bibliographystyle{unsrt}
\bibliography{references}


\end{document}